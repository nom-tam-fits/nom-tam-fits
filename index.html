<!DOCTYPE html>
<!--
 | Generated by Apache Maven Doxia Site Renderer 1.11.1 from src/site/markdown/index.md at 2023-09-12
 | Rendered using Apache Maven Fluido Skin 1.9
-->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="Apache Maven Doxia Site Renderer 1.11.1" />
    <title>nom-tam-fits &#x2013; </title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-1.9.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />
    <script src="./js/apache-maven-fluido-1.9.min.js"></script>
  </head>
  <body class="topBarDisabled">
    <a href="https://github.com/nom-tam-fits/nom-tam-fits">
      <img style="position: absolute; top: 0; right: 0; border: 0; z-index: 10000;"
        src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"
        alt="Fork me on GitHub">
    </a>
    <div class="container-fluid">
      <header>
        <div id="banner">
          <div class="pull-left"><div id="bannerLeft"><img src="images/fits_logo_text.png"  alt=""/></div>
</div>
          <div class="pull-right"></div>
          <div class="clear"><hr/></div>
        </div>

        <div id="breadcrumbs">
          <ul class="breadcrumb">
        <li id="publishDate">Last Published: 2023-09-12<span class="divider">|</span>
</li>
      <li class=""><a href="index.html" title="nom.tam.fits">nom.tam.fits</a><span class="divider">/</span></li>
    <li class="active "></li>
      <li id="projectVersion" class="pull-right">Version: 1.18.1</li>
          </ul>
        </div>
      </header>
      <div class="row-fluid">
        <header id="leftColumn" class="span2">
          <nav class="well sidebar-nav">
  <ul class="nav nav-list">
   <li class="nav-header">Documentation</li>
    <li class="active"><a href="#"><span class="none"></span>Getting Started</a></li>
    <li><a href="apidocs/index.html" title="API Documentation"><span class="none"></span>API Documentation</a></li>
    <li><a href="download.html" title="Download"><span class="none"></span>Download</a></li>
    <li><a href="changes-report.html" title="Changes"><span class="none"></span>Changes</a></li>
    <li><a href="about.html" title="About"><span class="none"></span>About</a></li>
   <li class="nav-header">Project Documentation</li>
    <li><a href="project-info.html" title="Project Information"><span class="icon-chevron-right"></span>Project Information</a></li>
    <li><a href="project-reports.html" title="Project Reports"><span class="icon-chevron-right"></span>Project Reports</a></li>
  </ul>
          </nav>
          <div class="well sidebar-nav">
            <hr />
            <div id="poweredBy">
              <div class="clear"></div>
              <div class="clear"></div>
              <div class="clear"></div>
<a href="http://maven.apache.org/" title="Maven" class="builtBy"><img class="builtBy"  alt="Maven" src="http://maven.apache.org/images/logos/maven-feather.png"    /></a>
            </div>
          </div>
        </header>
        <main id="bodyColumn"  class="span10" >
<p><img src="https://github.com/nom-tam-fits/nom-tam-fits/actions/workflows/maven.yml/badge.svg" alt="Build Status" />
<a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits/actions/workflows/site.yml"><img src="https://github.com/nom-tam-fits/nom-tam-fits/actions/workflows/site.yml/badge.svg" alt="Project Site" /></a>
<a class="externalLink" href="https://codecov.io/gh/nom-tam-fits/nom-tam-fits"><img src="https://codecov.io/gh/nom-tam-fits/nom-tam-fits/branch/master/graph/badge.svg?token=8rFyA5YzE5" alt="codecov" /></a>
<a class="externalLink" href="https://maven-badges.herokuapp.com/maven-central/gov.nasa.gsfc.heasarc/nom-tam-fits"><img src="https://maven-badges.herokuapp.com/maven-central/gov.nasa.gsfc.heasarc/nom-tam-fits/badge.svg" alt="Maven Central" /></a></p>
<h1>Getting started with the <i>nom.tam.fits</i> library.</h1>
<p>Updated for 1.18.1 and/or later 1.x releases.</p><section>
<h2><a name="Table_of_Contents"></a>Table of Contents</h2>
<ul>

<li><a href="#related-links">Related Links</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#reading-fits-files">Reading FITS files</a></li>
<li><a href="#writing-data">Writing FITS data</a></li>
<li><a href="#modifying-existing-files">Modifying existing FITS files</a></li>
<li><a href="#building-tables-from-data">Buliding binary tables from local data</a></li>
<li><a href="#fits-headers">FITS headers</a></li>
<li><a href="#compression-support">Compression support</a></li>
<li><a href="#contribute">How to contribute</a></li>
</ul><hr />
<p><a name="related-links"></a></p></section><section>
<h2><a name="Related_links"></a>Related links</h2>
<p>You may find the following links useful:</p>
<ul>

<li><a class="externalLink" href="https://nom-tam-fits.github.io/nom-tam-fits/apidocs/index.html">API documentation</a></li>
<li><a class="externalLink" href="https://fits.gsfc.nasa.gov/fits_standard.html">FITS Standard</a></li>
<li><a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits/releases">Releases</a></li>
<li><a class="externalLink" href="https://nom-tam-fits.github.io/nom-tam-fits/changes-report.html">History of changes</a></li>
<li><a class="externalLink" href="https://nom-tam-fits.github.io/nom-tam-fits/index.html">Project site</a></li>
<li><a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits">Github repository</a></li>
<li><a class="externalLink" href="https://mvnrepository.com/artifact/gov.nasa.gsfc.heasarc/nom-tam-fits">Maven Central repository</a></li>
</ul><hr />
<p><a name="introduction"></a></p></section><section>
<h2><a name="Introduction"></a>Introduction</h2>
<ul>

<li><a href="#fits-data-type">FITS data (HDU) types</a></li>
<li><a href="#fits-vs-java-data-types">FITS vs Java data types</a></li>
</ul>
<p>FITS (Flexible Image Transport System) is a binary format devised and primarily used for the storage of astronomical
datasets. A FITS file is composed of one or more <i>Header-Data Units</i> (HDUs). Each HDU consists of a <i>header</i>, which
describes the data and possibly contain extra metadata (as key-value pairs) or comments, and a <i>data</i> section.</p>
<p>The library requires a level of familiarity with FITS and its common standards and conventions for effective use. For
example, while the library will automatically interpret and populate the mandatory minimum data description in FITS
headers, it will not automatically process optional standard or conventional header entries. It is up to the users to
extract or complete the description of data to its full extent, for example to include FITS world coordinate systems
(WCS), physical units, etc. Users are encouraged to familiarize themselves with the
<a class="externalLink" href="https://fits.gsfc.nasa.gov/fits_standard.html">FITS standard</a> and conventions described therein to be effective users
of this library.</p>
<p>This library was originally written in Java 1.0 and therefore its design and implementation were strongly influenced
by the limited functionality and efficiencies of early versions of Java.</p>
<p>This is an open-source, community maintained, project hosted on github as
<a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits">nom-tam-fits</a>. Further information and documentation, including API
docs, can be found on the <a class="externalLink" href="https://nom-tam-fits.github.io/nom-tam-fits/index.html">project site</a>.</p>
<p><a name="Fits-data-types"></a></p><section>
<h3><a name="FITS_data_.28HDU.29_types"></a>FITS data (HDU) types</h3>
<p>The current FITS standard (4.0) recognizes the following principal HDU / data types:</p>
<ol style="list-style-type: decimal">

<li>

<p><b>Image</b> can store a regular array of 1-999 dimensions with a type corresponding to Java numerical primitives,
such as a one-dimensional time series of samples (e.g. <code>int[]</code>), or a three-dimensional cube of voxels (e.g.
<code>float[][][]</code>). (Note, that Java supports images up to 255 dimensions only but it's unlikely you'll find that
limiting for your application.)</p>
</li>
<li>

<p><b>Binary Table</b> can store rows and columns of assorted of elements. Each column entry may be either a single
value, or a fixed-sized (multidimensional) array, or else a variable-length 1D arrays of a given type. All Java
primitive numerical types are supported, but also <code>String</code>, <code>Boolean</code> (logical), <code>boolean</code> (bits), and <code>ComplexValue</code>
types.</p>
</li>
<li>

<p><b>ASCII Table</b> (<i>discouraged</i>) is a simpler, less capable table format with support for storing singular
primitive numerical types, and Strings only &#x2013; in human-readable format. You should probably use the more flexible
(and more compact) binary tables instead for your application, and reserve use of ASCII tables for reading data that
may still contain these.</p>
</li>
<li>

<p><b>Random Groups</b> (<i>discouraged</i>) can contain a set of images of the same type and dimensions along with a set of
parameters of the same type (for example an <code>int[][]</code> image, along with a set of <code>int</code> parameters). They were never
widely used and the FITS 4.0 standard discourages them going forward, given that binary tables provide far superior
capabilities for storing the same type of data. Support for these type of HDUs is thus very basic, and aimed mainly
at providing a way to access data that was already written in this format.</p>
</li>
<li>

<p><b>Foreign File</b> can encapsulate various other files within the FITS. Foreign file HDUs are a recognised
convention, but not (yet) officially part of the FITS standard. We do not explicitly support foreign file
encapsulation yet, but it is something that we are considering for a future release.</p>
</li>
</ol>
<p>In addition to the basic HDU types, there are extension of table HDUs that serve specific purposes, such as:</p>
<ul>

<li>

<p><b>Compressed Images / Tables</b> are an extension of the binary table HDUs for storing an image or a binary table in
a compressed format, with tiling support to make parts easily accessible from the whole. We provide full support for
compressing and decompressing images and tables, and for accessing specific regions of compressed data stored in this
format.</p>
</li>
<li>

<p>The <b>Hierarchical Grouping</b> convention is an extension of table HDUs (ASCII or binary) for storing information on
the hierarchical relation of HDUs contained within (or external to) the FITS. The hierarchical grouping is a
recognized convention, but not (yet) officially part of the FITS standard. We do not explicitly support this
convention yet, but it is something that we are considering for a future release.</p>
</li>
</ul>
<p><a name="fits-vs-java-data-types"></a></p></section><section>
<h3><a name="FITS_vs_Java_data_types"></a>FITS vs Java data types</h3><section>
<h4><a name="Signed_vs_unsigned_bytes"></a>Signed vs unsigned bytes</h4>
<p>Java bytes are signed, but FITS bytes are not. If any arithmetic processing is to be done on byte valued data,
users may need to be careful of Java&#x2019;s automated conversion of signed bytes to widened integers. Thus, a value of
<code>0xFF</code>would signify 255 in FITS, but has a Java value of -1. To preserve the FITS meaning, we may upconvert it to
<code>short</code> as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  short shortValue = (byteValue &amp; 0xFF);
</code></pre></div>
<p>This idiom of AND-ing the byte values with <code>0xFF</code> before a widening conversion is generally the way to prevent
undesired sign extension of bytes.</p></section><section>
<h4><a name="Strings"></a>Strings</h4>
<p>FITS generally represents character strings as byte arrays of ASCII characters, with legal values between <code>0x20</code> and
<code>0x7E</code> (inclusive). The library automatically converts between Java <code>String</code>s and their FITS representations, by the
appropriate narrowing conversion of 16-bit Unicode <code>char</code> to <code>byte</code>. Therefore, you should be careful to avoid using
extended Unicode characters (and also ASCII beyond the <code>0x20</code> &#x2013; <code>0x7E</code> range) in <code>String</code>s, when including these in
FITS.</p><hr />
<p><a name="reading-fits-files"></a></p></section></section></section><section>
<h2><a name="Reading_FITS_files"></a>Reading FITS files</h2>
<ul>

<li><a href="#deferred-reading">Deferred reading</a></li>
<li><a href="#read-tolerance">Tolerance to standard violations in 3rd party FITS files</a></li>
<li><a href="#reading-images">Reading images</a></li>
<li><a href="#reading-tables">Reading tables</a></li>
</ul>
<p><a name="deferred-reading"></a></p><section>
<h3><a name="Deferred_reading"></a>Deferred reading</h3>
<p>When FITS data are being read from a non-compressed random accessible input (such as a <code>FitsFile</code>), the <code>read()</code> call
will parse all HDU headers but will typically skip over the data segments (noting their position in the file however).
Only when the user tries to access data from an HDU, will the library load that data from the previously noted file
position. The behavior allows to inspect the contents of a FITS file very quickly even when the file is large, and
reduces the need for IO when only parts of the whole are of interest to the user. Deferred input, however, is not
possible when the input is compressed or if it is uses an stream rather than a random-access <code>FitsFile</code>.</p>
<p>One thing to keep in mind with deferred reading is that you should not close your <code>Fits</code> or its random-accessible
input file before all the required data has been loaded. For example, the following will cause an error:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits fits = new Fits(&quot;somedata.fits&quot;);
   
  // Scans the FITS, but defers loading data until we need it
  fits.read();
   
  // We close the FITS prematurely.
  fits.close();
   
  // !!!BAD!!! now if  we try to access data
  //           we'll get and exception...
  float[][] image = (float[][]) fits.getHDU(0).getKernel(); 
</code></pre></div>
<p>In the above, the <code>getKernel()</code> method will try to load the deferred data from the input that we closed just before
it. That's not going to work. The correct order is of course:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Scans the FITS, but defers loading data until we need it
  fits.read();
 
  // Good, the FITS is still open so we can get the deferred data
  float[][] image = (float[][]) fits.getHDU(0).getKernel(); 

  // We close only after we grabbed all the data we needed.
  fits.close();
</code></pre></div>
<p>As of version <b>1.18</b>, all data classes of the library support deferred reading.</p>
<p><a name="read-tolerance"></a></p></section><section>
<h3><a name="Tolerance_to_standard_violations_in_3rd_party_FITS_files."></a>Tolerance to standard violations in 3rd party FITS files.</h3>
<p>By default the library will be tolerant to FITS standard violations when parsing 3rd-party FITS files. We believe that
if you use this library to read a FITS produced by other software, you are mainly interested to find out what's inside
it, rather than know if it was written properly. However, problems such as missing padding at the end of the file, or
an unexpected end-of-file before content was fully parsed, will be logged so they can be inspected. Soft violations of
header standards (those that can be overcome with educated guesses) are also tolerared when reading, but logging for
these is not enabled by default (since they may be many, and likely you don't care). You can enable logging standard
violations in 3rd-party headers by <code>Header.setParserWarningsEnabled(true)</code>. You can also enforce stricter compliance
to standard when reading FITS files via <code>FitsFactory.setAllowHeaderRepairs(false)</code> and
<code>FitsFactory.setAllowTerminalJunk(false)</code>. When violations are not tolerated, appropriate exceptions will be thrown
during reading.</p>
<p><a name="reading-images"></a></p></section><section>
<h3><a name="Reading_Images"></a>Reading Images</h3>
<ul>

<li><a href="#reading-whole-images">Reading whole images</a></li>
<li><a href="#reading-cutouts">Reading selected parts of images only (cutouts)</a></li>
<li><a href="#streaming-cutouts">Streaming image cutouts</a></li>
<li><a href="#low-level-image-read">Low-level reading of image data</a></li>
</ul>
<p><a name="reading-whole-images"></a></p><section>
<h4><a name="Reading_whole_images"></a>Reading whole images</h4>
<p>The simplest example of reading an image contained in the first HDU is given below:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;myfile.fits&quot;);
  ImageHDU hdu = (ImageHDU) f.readHDU();
  int[][] image = (int[][]) hdu.getKernel();
</code></pre></div>
<p>First we create a new instance of <code>Fits</code> with the filename. Then we can get first HDU using the <code>getHDU()</code> method.
Note the casting into an <code>ImageHDU</code>.</p>
<p>When reading FITS data using the nom.tam library the user will often need to cast the results to the appropriate type.
Given that the FITS file may contain many different kinds of data and that Java provides us with no class that can
point to different kinds of primitive arrays other than <code>Object</code>, such explicit casting is inevitable if you want to
use the data from the FITS files.</p>
<p><a name="reading-cutouts"></a></p></section><section>
<h4><a name="Reading_selected_parts_of_an_image_only_.28cutouts.29"></a>Reading selected parts of an image only (cutouts)</h4>
<p>Since ersion <b>1.18</b>, it is possible to read select cutouts of large images, including sparse sampling of specific
image regions. When reading image data users may not want to read an entire array especially if the data is very
large. An <code>ImageTiler</code> can be used to read in only a portion of an array. The user can specify a box (or a sequence of
boxes) within the image and extract the desired subsets. <code>ImageTiler</code> can be used for any image. The library will try
to only read the subsets requested if the FITS data is being read from an uncompressed file but in many cases it will
need to read in the entire image before subsetting.</p>
<p>Suppose the image we retrieve above has 2000x2000 pixels, but we only want to see the innermost 100x100 pixels. This
can be achieved with</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  ImageTiler tiler = hdu.getTiler();
  short[] center = (short[]) tiler.getTile(new int[] {950, 950}, new int[] {100, 100});
</code></pre></div>
<p>The tiler needs to know the corners and size of the tile we want. Note that we can tile an image of any
dimensionality. <code>getTile()</code> returns a one-dimensional array with the flattened 1D image. You can convert it to a 2D
image afterwards using <code>ArrayFuncs.curl()</code>, e.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  short[][] center2D = (short[][]) ArrayFuncs.curl(center, 100, 100);
</code></pre></div>
<p><a name="reading-streaming-cutouts"></a></p></section><section>
<h4><a name="Streaming_image_cutouts"></a>Streaming image cutouts</h4>
<p>Since version <b>1.18</b> it is also possible to stream cutouts, using the <code>StreamingTileImageData</code> class. The streaming
can be used with any source that implements the <code>RandomAccessFileIO</code> interface, which provides file-like random
access, for example for a resource on the Amazon S3 cloud:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  import nom.tam.util.RandomAccessFileIO;

  public final class S3RandomAccessFileIO implements RandomAccessFileIO {
      // ...
  }
</code></pre></div>
<p>Below is an example code sketch for streaming image cutouts from a very large image residing on Amazon S3:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits source = new Fits(new S3RandomAccessFileIO(...));
  ImageHDU imageHDU = source.getHDU(...);
  
  // Manually set up the header for the cutout image as necessary
  Header cutoutHeader = ...
  
  // Define the image cutout region we want 
  int[] tileStarts, tileLengths, tileSteps;
  ...

  // Create the cutout with the specified parameters
  StreamingTileImageData streamingTileImageData = new StreamingTileImageData(
      cutoutHeader, imageHDU.getTiler(), tileStarts, tileLengths, tileSteps
  );
      
  // Add the cutout region to a new FITS object
  Fits output = new Fits();
  output.addHDU(FitsFactory.hduFactory(cutoutHeader, streamingTileImageData));
      
  // The cutout is processed at write time!  
  output.write(outputStream);
</code></pre></div>
<p>As of version <b>1.18</b> it is also possible to stream cutouts from compressed images using the <code>CompressedImageTiler</code>
class. Whereas the <code>asImageHDU()</code> method decompresses the entire image in memory, the <code>CompressedImageTiler</code> will
decompress only the tiles necessary for obtaining the desired cutout. For example, consider writing the cutout from a
compressed image as a regular non-compressed <code>ImageHDU</code>. This can be achieved much the same way as in the above
example, replacing <code>imageHDU.getTiler()</code> with a <code>CompressedImageTiler</code> step, such as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  ...
  CompressedImageTiler compressedImageTiler = new CompressedImageTiler(compressedImageHDU);
  StreamingTileImageData streamingTileImageData = new StreamingTileImageData(
      cutoutHeader, compressedImageTiler, corners, lengths, steps
  );
  ...
</code></pre></div>
<p><a name="low-level-image-read"></a></p></section><section>
<h4><a name="Low-level_reading_of_image_data"></a>Low-level reading of image data</h4>
<p>Suppose we want to get the average value of a 100,000 x 40,000 pixel image. If the pixels are 32-bit integers, that
would be an 16 GB file. However, we do not need to load the entire image into memory at once. Instead we can analyze
it via bite-sized chunks. For example, we start by finding the beginning of the relevant data segment in the file:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits fits = new Fits(&quot;bigimg.fits&quot;);
  ImageHDU img = fits.getHDU(0);
  
  // Rewind the stream to the beginning of the data segment
  if (!img.getData().reset()) {
      // Uh-oh...
      throw new IllegalStateException(&quot;Unable to seek to data start&#x201d;);
  }
</code></pre></div>
<p>The <code>reset()</code> method causes the internal stream to seek to the beginning of the data area. If that&#x2019;s not possible it
returns <code>false</code>. Next, we obtain the input file or stream for reading, query the image size, and set up our
chunk-sized storage (e.g. by image row):</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Get the input associated to the FITS
  ArrayDataInput in = fits.getStream();
  
  int[] dims = img.getAxes();      // the image dimensions
  int[] chunk = new int[dims[1]];  // a buffer for a row of data
</code></pre></div>
<p>Now we can cycle through the image rows (or chunks) and collect the statistics as we go, e.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  long sum = 0;

  for (int row = 0; row &lt; dims[0]; row++) {
      in.readLArrayFully(chunk); 
      for (int i = 0; i &lt; chunk.length; i++) {
          sum += line[i];
      }
  }
      
  // Return the average value
  return (double) sum / (dims[0] * dims[1]);
</code></pre></div>
<p><a name="reading-tables"></a></p></section></section><section>
<h3><a name="Reading_Tables"></a>Reading Tables</h3>
<p>The easiest and safest way to access data in tables, is by individual entries. Typically, we start by identifying our
table HDU in the FITS:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;mytable.fits&quot;);

  // Say, our table is the first extension HDU...
  TableHDU hdu = (TableHDU) f.getHDU(1);
</code></pre></div>
<p>If we are using a random-accessible input (like the file above), we have the option (for binary tables) to load the
entire table into memory first. This may be a good idea for small tables, and/or if we plan to access all the data
contained in the table &#x2013; or not such a good idea if we deal with huge tables from which we need only a selection of
the entries. To load the entire HDU into memory:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // This will load the main table and the heap area into memory (if we want to...)
  hdu.getKernel();
</code></pre></div>
<p>Next, we might want to find which columns store the data we need, using column names if appropriate. (We can of course
rely on hard-coded column indices too when we know we are dealing with tables of known fixed format).</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Find column indices by name and check that they exist...
  int colUTC = hdu.findColumn(&quot;UTC&quot;);
  if (colUTC &lt; 0) {
      // uh-oh, there is no such column...
  }
</code></pre></div>
<p>Now we can loop through the rows of interest and pick out the entries we need. For example, to loop through all table
rows to get only the scalar values from the column named <code>UTC</code> (see above), a phase value in the 4th column (Java
index 3), and a spectrum stored in the fifth column (i.e. Java index 4):</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Loop through rows, accessing the relevant column data
  for(int row = 0; row &lt; tab.getNRows(); row++) {
  
      // Retrieve scalar entries with convenient getters... 
      double utc  = tab.getDouble(row, colUTC);
           
      // We can also access by fixed column index...
      ComplexValue phase = (ComplexValue) tab.get(row, 3);
      ComplexValue[] spectrum = (ComplexValue[]) tab.get(row, 4);
      
      // process the data...
      ...
  }
</code></pre></div>
<p>The old <code>getElement()</code> / <code>setElement()</code> methods supported access as arrays only. While this is still a viable
alternative (though slightly less elegant), we recommend against it going forward. Nevetheless, the equivalent to the
above using this approach would be:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Loop through rows, accessing the relevant column data
  for(int row = 0; row &lt; tab.getNRows(); row++) {
  
      // Retrieve scalar entries by casting the element to the correct array 
      // type, and returning the first (and only) element from that array...
      double utc  = ((double[]) tab.getElement(row, colUTC))[0];
      
      // We can also access by fixed column index...
      float[] phase = ((float[]) tab.getElement(row, 3));
      float[][] spectrum = (float[][]) tab.getElement(row, 4);
      
      // process the data...
      ...
  }
</code></pre></div>
<p>These older methods (<code>getElement()</code>, <code>getRow()</code> and <code>getColumn()</code>) always return table data as arrays, even
for scalar types, so a single integer entry will be returned as <code>int[1]</code>, a single string as <code>String[1]</code>. Complex
values are stored as <code>float[2]</code> or <code>double[2]</code> depending on  the precision (FITS type <code>C</code> or <code>M</code>). So, a
double-precision FITS complex array of size <code>[5][7]</code> will be returned a <code>double[5][7][2]</code>. Logicals return <code>boolean[]</code>,
which means that while FITS supports <code>null</code> logical values, we don't and these will default to <code>false</code>. (However,
the <code>get()</code> method introduced in version <b>1.18</b> will return these as <code>Boolean</code> arrays instead, retaining <code>null</code>
values appropriately!).</p>
<p>Note that for best performance you should access elements in monotonically increasing order when in deferred mode &#x2013; at
least for the rows, but it does not hurt to follow the same principle for columns inside the loops also. This will help
avoid excess buffering that way be required at times for backward jumps.</p>
<p>The library provides methods for accessing entire rows and columns also via the <code>TableData.getRow(int)</code> and
<code>TableData.getColumn(int)</code> or <code>BinaryTable.getColumn(String)</code> methods. However, we recommend against using these going
forward because these methods return data that may be confounding to interpret, with non-trivial data types and/or
dimensions.</p><hr />
<p><a name="writing-data"></a></p></section></section><section>
<h2><a name="Writing_FITS_data"></a>Writing FITS data</h2>
<ul>

<li><a href="#writing-files">Writing complete FITS files</a></li>
<li><a href="#incremental-writing">Writing one HDU at a time</a></li>
<li><a href="#low-level-writes">Low-level writes</a></li>
</ul>
<p><a name="writing-files"></a></p><section>
<h3><a name="Writing_complete_FITS_files"></a>Writing complete FITS files</h3>
<p>When creating FITS files from data we have at hand, the easiest is to start with a <code>Fits</code> object. We can add to it
image and/or table HDUs we create. When everything is assembled, we write the FITS to a file or stream:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits fits = new Fits();

  fits.addHDU(...);
  ...
 
  fits.write(&quot;myfits.fits&quot;);
</code></pre></div>
<p>Images can be added to the FITS at any point. For example, consider a 2D <code>float[][]</code> image we want to  add to a FITS:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  float[][] image ...
  
  ImageHDU imageHDU = fits.makeHDU(image);
  fits.addHDU(imageHDU);
</code></pre></div>
<p>The <code>makeHDU()</code> method only populates the essential descriptions of the image in the HDU's header. We may want to
complete that description (e.g. add WCS information, various other data descriptions) to the new HDU's header, e.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Header header = imageHDU.getHeader();
  
  header.addValue(Standard.BUNIT, &quot;Jy/beam&quot;);
  ...
</code></pre></div>
<p>After that we can add further images or table(s), such as binary tables (preferred) or ASCII tables. Once all HDUs
have been assembled this way, we write the FITS as usual:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  fits.write(&quot;myfits.fits&quot;);
  fits.close();
</code></pre></div>
<p>An important thing to remember is that while images can be anywhere in the FITS files, tables are extensions, and so,
they may not reside in the first HDU in a file. Thus, if a table is the first HDU we add to a FITS container, it will
be automatically prepended by a dummy primary HDU, and our data will actually be written as the second HDU (Java index
1).</p><section>
<h4><a name="Binary_versus_ASCII_tables"></a>Binary versus ASCII tables</h4>
<p>When writing simple tables it may be possible to write the tables in either binary or ASCII format, provided all
columns are scalar types. By default, the library will create and write binary tables for such data. To create ASCII
tables instead the user should call <code>FitsFactory.setUseAsciiTables(true)</code> first. Given the superiority and
compactness of binary tables, we recommend against using ASCII tables, unless you have to for a compelling reason.</p>
<p><a name="incremental-writing"></a></p></section></section><section>
<h3><a name="Writing_one_HDU_at_a_time"></a>Writing one HDU at a time</h3>
<p>Sometimes you do not want to add all your HDUs to a <code>Fits</code> object before writing them out to a file or stream. Maybe
because they use up too much RAM, or you are recording from a live stream and want to add HDUs to the file as they
come in. As of version <b>1.17</b> of the library, you can write FITS files one HDU at a time without having to place
them in a <code>Fits</code> container first, or having to worry about the mandatory keywords having been set for primary or
extension HDUs. Or, you can write a <code>Fits</code> object with some number of HDUs, but then keep appending further HDUs
after, worry-free. The <code>FitsFile</code> or <code>FitsOutputStream</code> object will keep track of where things go in the file or
stream, and set the required header keywords for the appended HDUs as appropriate for a primary or extension HDU
automatically.</p>
<p>Here is an example of how ro create a FITS file HDU-by-HDU without the need for a <code>Fits</code> object as a holding
container:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Create the file to which to write the HDUs as they come
  FitsFile out = new FitsFile(&quot;my-incremental.fits&quot;, &quot;rw&quot;);
  ...

  // you can append 'hdu' objects to the FITS file (stream) as:
  // The first HDU will be set primary (if possible), and following HDUs will be extensions. 
  hdu.write(out);
  ...

  // When you are all done you can close the FITS file/stream
  out.close(); 
</code></pre></div>
<p>In the above case the <code>FitsFile</code> output is random accessible, which means you can go back and re-write HDUs (or their
headers) in place later. If you do go all the way back to the head of the file, and re-write the first HDU, you can be
assured that it will contain the necessary header entries for a primary HDU, even if you did not set them yourself.
Easy as pie.</p>
<p>Of course, you can use a <code>FitsOutputStream</code> as opposed to a file as the output also, e.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  FitsOutputStream out = new FitsOutputStream(new FileOutputStream(&quot;my-incremental.fits&quot;));
  ...
</code></pre></div>
<p>in which case going back ro re-write what was already written before is not an option.</p>
<p><a name="low-level-writes"></a></p></section><section>
<h3><a name="Low-level_writes"></a>Low-level writes</h3>
<p>When a large table or image is to be written, the user may wish to stream the write. This is possible but rather
more difficult than in the case of reads.</p>
<p>There are two main issues:</p>
<ol style="list-style-type: decimal">

<li>

<p>The header for the HDU must written to show the size of the entire file when we are done.
Thus the user may need to modify the header data appropriately.</p>
</li>
<li>

<p>After writing the data, a valid FITS file may need to be padded to an appropriate length.</p>
</li>
</ol>
<p>It's not hard to address these requirements, but the user needs some familiarity with the internals of the FITS
representation.</p><section>
<h4><a name="Images"></a>Images</h4>
<p>We can write images one subarray at a time, if we want to. Here is an example of
how you could go about it. First, create storage for the contiguous chunk we want
to write at a time. For example, same we want to write a 32-bit floating-point image
with <code>[nRows][nCols]</code> pixels, and we want to write these one row at a time:</p>
<p>First let's create storage for the chunk:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // An array to hold data for a chunk of the image...
  float[] chunk = new float[nCols];
</code></pre></div>
<p>Next create a header. It's easiest to create it from the chunk, and then just
modify the dimensions for the full image, e.g. as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Create an image HDU with the row 
  BasicHDU hdu = Fits.makeHDU(row);
  Header header = hdu.getHeader();

  // Override the image dimensions in the header to describe the full image
  ImageData.overrideHeaderAxes(header, nRow, nCol); 
</code></pre></div>
<p>Next, we can complete the header description adding whatever information we desire.
Once complete, we'll write the image header to the output:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Create a FITS and write to the image to it
  FitsFile out = new FitsFile(&quot;image.fits&quot;, &quot;rw&quot;);
  header.write(out);
</code></pre></div>
<p>Now, we can start writing the image data, iterating over the rows, populating our
chunk data in turn, and writing it out as we go.</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Iterate over the image rows
  for (int i = 0; i &lt; nRows; i++) {
     // fill up the chunk with one row's worth of data
     ...

     // Write the row to the output
     out.writeArray(chunk);
  }
</code></pre></div>
<p>Finally, add the requisite padding to complete the FITS block of 2880 bytes
after the end of the image data:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  FitsUtil.pad(out, out.position());
  out.close();
</code></pre></div></section><section>
<h4><a name="Tables"></a>Tables</h4>
<p>We can do something pretty similar for tables <i>so long as we don't have variable length columns</i>, but
it requires a little more work.</p>
<p>First we have to make sure we are not trying to write tables into the primary HDU of a FITS. Tables
can only reside in extensions, and so we might need to create and write a dummy primary HDU to the
FITS before we can write the table itself:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  FitsFile out = new FitsFile(&quot;table.fits&quot;, &quot;rw&quot;);

  // Binary tables cannot be in the primary HDU of a FITS file
  // So we must add a dummy primary HDU to the FITS first if necessary
  new NullDataHDU().write(out);
</code></pre></div>
<p>Next, assume we have a binary table that we either read from an input, or else assembled ourselves
(see further below on how to build binary tables):</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  BinaryTable table = ...
</code></pre></div>
<p>Next, we will need to create an appropriate FITS header for the table:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Header header = new Header();
  table.fillHeader(header);
</code></pre></div>
<p>We can now complete the header descriprtion as we see fit, with whatever optional entries. We can also
save space for future additions, e.g. for values we will have only after we start writing the table
data itself:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   // Make space for at least 200 more header lines to be added later
   header.ensureCardSpace(200);
</code></pre></div>
<p>Now, we can write out the header:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   header.write(out);
</code></pre></div>
<p>Next, we can finally write regular table rows (without variable-length entries) in a loop. Assuming
that our row is something like <code>{ { double[1] }, { byte[10] }, { float[256] }, ... }</code>:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  for (...) {
     // Write data one element at the time into the buffer via the 
     // rowStream. These must match the column structure of the table, 
     // in terms of order, data types, and element counts. 

     out.writeDouble(ra);
     out.write(fixedLengthNameBytes);
     out.witeArray(spectrum);
     ...
  }
</code></pre></div>
<p>We want to keep count of the rows we write (e.g. <code>nRowsWritten</code>). Once we finish writing the table data,
we must add the requisite padding to complete the FITS block of 2880 bytes after the table data ends.</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Add padding to the file to complete the FITS block
  FitsUtil.pad(out, nRowsWritten * table.getRegularRowSize());
</code></pre></div>
<p>After the table has been thus written to the output, we should make sure that the header has the correct number
of table rows in in <code>NAXIS2</code> entry:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  header.addValue(Standard.NAXISn.n(2), nRowsWritten);
</code></pre></div>
<p>We can also complete the header with any other information that became available since the start (using the space
we reserved for additions earlier). Once the header is all in ship-shape, we can re-write in the file at its original
location:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   // Re-write the header with the new information we added since we began writing 
   // the table data
   header.rewrite();
</code></pre></div><hr />
<p><a name="modifying-existing-files"></a></p></section></section></section><section>
<h2><a name="Modifying_existing_FITS_files"></a>Modifying existing FITS files</h2>
<p>An existing FITS file can be modified in place in some circumstances. The file must be an uncompressed
(random-accessible) file, with permissions to read and write. The user can then modify elements either by directly
modifying the kernel data object for image data, or by using the <code>setElement</code> or similar methods for tables.</p>
<p>Suppose we have just a couple of specific elements we know we need to change in a given file:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;mod.fits&quot;);
     
  ImageHDU hdu = (ImageHDU) f.getHDU(0);
  int[][] img = (int[][]) hdu.getKernel();
     
  // modify the image as needed...
  img[i][j] = ...
  ...
  
  // No write the new data back in the place of the old
  hdu.rewrite();
</code></pre></div>
<p>Same goes for a table HDU:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  BinaryTableHDU hdu = (BinaryTableHDU) f.getHDU(1);
  
  // Modify the table as necessary
  hdu.set(3, 0, 3.14159265);
  ...
  
  // Make sure the file contains the changes made above
  hdu.rewrite();
</code></pre></div>
<p>Note, that in the above table example, the <code>rewrite()</code> call may be superfluous since <code>BinaryTable.set()</code> may be
editing the file in situ if the data has been left in deferred-read mode (random accessible file, without data loaded
to memory). Nevertheless, it is best practice to call <code>rewrite()</code> anyway to ensure that the updates are synched to the
output under all circumstances. And, you should also close the output (e.g. via <code>Fits.close()</code>) after done editing the
FITS file to ensure that any pending file changes are fully flushed to the output.</p>
<p>Defragmenting binary tables allows to reclaim heap space that is no longer used in the heap area. When deleting
variable-length columns, or when replacing entries inside variable-length columns, some or all of the space occupied
by old entries on the heap may become orphanes storage, needlessly bloating the heap storage. Also, changed entries
may be placed on the heap out of order, which can slow down caching effectiveness for sequential table acces. Thus
when modifying tables with variable-length columns, it may be a good idea to defragment the heap before writing in to
the output. For the above example, this would be adding an extra step before <code>rewrite)</code>.</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  ...
  
  // If we changed variable-length data, it may be a good
  // idea to defragment the heap before writing...
  hdu.defragment();

  hdu.rewrite();
</code></pre></div>
<p>Defragmenting might also be a good idea when building tables with variable-length data column by column (as
opposed to row-by-row).</p>
<p>And, headers can also be updated in place also &#x2013; you don't even need to access the data, which can be left in
deferred state:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  BasicHDU&lt;?&gt; hdu = f.getHDU(1);
  Header header = hdu.getHeader();
  
  header.addValue(Standard.TELESCOP, &quot;SMA&quot;).comment(&quot;The Submillimeter Array&quot;);
  header.addValue(Standard.DATE-OBS, FitsDate.now());
  ...
  
  header.rewrite();
</code></pre></div>
<p>Generally rewrites can be made as long as the only change is to the data content, but not to the data size
(and the FITS file meets the criteria mentioned above). An exception will be thrown if the data has been added
or deleted or too many changes have been made to the header. Some additions to the header may be allowed as long as
the header still fits in the same number of FITS blocks (of 2880 bytes) as before. (Hint, you can always reserve
space in headers for later additions using <code>Header.ensureCardSpace(int)</code> prior to writing the header or HDU
originally.)</p><hr />
<p><a name="building-tables-from-data"></a></p></section><section>
<h2><a name="Building_binary_tables_from_local_data"></a>Building binary tables from local data</h2>
<ul>

<li><a href="#build-row-col-data">Making HDUs from existing row-column format data</a></li>
<li><a href="#building-by-row">Buiding tables row-by-row</a></li>
<li><a href="#building-by-column">Buiding tables column-by-column</a></li>
</ul>
<p><a name="build-row-col-data"></a></p><section>
<h3><a name="Making_HDUs_from_existing_row-column_format__data"></a>Making HDUs from existing row-column format  data</h3>
<p>If you already have an <code>Object[rows][cols]</code> data table, in which each entry represents data for a row and column,
you can create an appropriate binary table HDU from it as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   Object[][] tableData = ...
  
   BinaryTableHDU hdu = BinaryTableHDU.wrap(BinaryTable.fromRowMajor(tableData));
</code></pre></div>
<p>There are some requirements on the array though:</p>
<ul>

<li>All rows must contain the same number of columns</li>
<li>The entries for the same column in each row must match in their type</li>
<li>All table entries must be any of:
<ul>

<li>One of the supported Java types <code>String</code>, <code>ComplexValue</code>), or</li>
<li>primitive arrays (e.g. <code>int[]</code>, <code>float[][]</code>), or</li>
<li>Arrays of <code>Boolean</code> (logicals), <code>String</code> or <code>ComplexValue</code>, such as <code>Boolean[][]</code> or <code>String[]</code>, or</li>
<li>Scalar primitives stored as arrays of 1 (e.g. <code>short[1]</code>).</li>
</ul>
</li>
<li>If entries are multi-dimensional arrays, all rows in a column must have the same dimensionality and shape. (If
not, they will be stored as variable-length arrays in flattened 1D format, where the shape may be lost).</li>
<li>If entries are one-dimensional, they can freely vary in size from row to row</li>
<li>Java <code>null</code> entries are allowed for <code>String</code> and <code>Boolean</code> (logical) types, but not for the other data types.
(these will map to empty strings or <i>undefined</i> logical values respectively)</li>
</ul>
<p>Note, that while the library supports ASCII tables, it is generally better to just use binary tables for storing table
data regardless. ASCII tables are more limited, and were meant to be readable from a console without needing any tools
to display. However, much has happened since the 1970s, and there is no truly compelling reason for using ASCII tables
today. Binary tables are simply better, because they:</p>
<ul>

<li>Offer more flexibility, and support more data types (such as complex values, variable sized arrays, and
multidimensional arrays).</li>
<li>Take up less space on disk</li>
<li>Can be compressed to an even smaller size</li>
</ul>
<p>To create ASCII tables (provided the data allows for it) you will need to call <code>FitsFactory.setUseAsciiTables(true)</code>
prior to calling <code>Fits.makeHDU()</code> or one of the factory methods to encapsulate a table data object.</p>
<p>When creating or modifying binary tables containing variable-length columns, defragmenting might also be a good idea
before writing out binary tables to a file or stream:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  tableHDU.getData().defragment();
</code></pre></div>
<p>just before calling <code>write()</code>.</p>
<p><a name="building-by-row"></a></p></section><section>
<h3><a name="Buiding_tables_row-by-row"></a>Buiding tables row-by-row</h3>
<p>As of version <b>1.18</b> building tables one row at a time is both easy and efficient &#x2013; and may be the least confusing
way to get tables done right. (In prior releases, adding rows to existing tables was painfully slow, and much more
constrained). You may want to start by defining the types and dimensions of the data (or whether variable-length) that
will be contained in each table column:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   BinaryTable table = new BinaryTable();
   
   // A column containing 64-bit floating point scalar values, 1 per row...
   table.addColumn(ColumnDesc.createForScalars(double.class));
   
   // A column containing 5x4 arrays of single-precision complex values...
   table.addColumn(ColumnDesc.createForArrays(ComplexValue.Float.class, 5, 4));
   
   // A column containing Strings of variable length using 32-bit heap pointers...
   table.addColumn(ColumnDesc.creatForVariableLength(String.class));
   
   ...
</code></pre></div>
<p>Defining columns this way is not always necessary before adding rows to the table. However, it is necessary if you
will have data that needs variable-length storage row-after-row; or if you want more control over specifics of the
column format. As such, it is best practice to define the columns explictly even if not strictly required for your
particular application.</p>
<p>Now you can populate the table with your data, one row at a time, using the <code>addRow()</code> method as many times over as
necessary:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   for (...) {
       // prepare the row data, making sure each row is compatible with prior rows...
       ...
   	
       // Add the row to the table
       table.addRow(...);
   }
</code></pre></div>
<p>As of version <b>1.18</b>, you may use Java boxed types (as an alternative to primitive arrays-of-one) to specify
primitive scalar table elements, including auto-boxing of literals or variables. You may also use <i>vararg</i> syntax for
adding rows if that is more convenient in your application. Thus, you may simply write:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   table.addRowEntries(1, 3.14159265);
</code></pre></div>
<p>to add a row consisting of an 32-bit integer, a double-precision floating point value (presuming your table has those
two types of columns). Prior to <b>1.18</b>, the same would have to have been written as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  table.addRow(new Object[] { new int[] {1}, new double[] {3.14159265} }; 
</code></pre></div>
<p>Tables built entirely row-by-row are naturally defragmented, as long as they are not modified subsequently.</p>
<p>Once the table is complete, you can wrap it in a HDU:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  BinaryTableHDU hdu = BinaryTableHDU.wrap(table);
</code></pre></div>
<p>which will populate the header with the requisite entries that describe the table. You can then edit the new header
to add any extra information (while being careful to not modify the essential table description). Note, that once the
table is encompassed in a HDU, it is generally not safe to edit the table data, since the library has no foolproof way
to keep the header description of the table perfectly in sync. Thus it is recommended that you create table HDUs only
after the table data has been fully populated.</p>
<p><a name="building-by-column"></a></p></section><section>
<h3><a name="Buiding_tables_column-by-column"></a>Buiding tables column-by-column</h3>
<p>Sometimes we might want to assemble a table from a selection of data which will readily consitute columns in the table.
We can add these as columns to an existing table (empty or not) using the <code>BinaryTable.addColumn(Object)</code> method.
For example, say we have two arrays, one a time-series of spectra, and a matching array of corresponding timestamps. We
can create a table with these (or add them to an existing table with a matching number of rows) as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   double[] timestamps = new double[nRows]; 
   ComplexValue[][] spectra = new ComplexValue[nRows][];
   ...
   
   BinaryTable tab = new BinaryTable();
   
   table.addColumn(timeStamps);
   table.addColumn(spectra);
</code></pre></div>
<p>There are just a few rules to keep in mind when constructing tables in this way:</p>
<ul>

<li>All columns added this way must contain the same number of rows</li>
<li>In column data, scalars are simply elements in a 1D primitive array, in which each entry contains
the scalar value for a given row. (I.e. unlike in the row-major table format required to create entire tables at
once, we do not have to wrap scalar values in self-contained arrays of 1)</li>
<li>Other than the above, the same rules apply as for creating HDUs from complete table data above.</li>
<li>If setting complex columns with arrays of <code>float[2]</code> or <code>double[2]</code> (the old way), you will want to call
<code>setComplexColumn(int)</code> afterwards for that column to make sure they are labeled properly in the FITS header
(rather than as real-valued arrays of <code>float</code> or <code>double</code>).</li>
<li>Similarly, if adding arrays of <code>boolean</code> values, you might consider calling <code>convertToBits(int)</code> on that
column for a more compact storage option of the <code>true</code>/<code>false</code> values, rather than as 1-byte FITS logicals
(default).</li>
</ul>
<p>Defragmenting might also be a good idea before writing binary tables with variable-length data built column by column
(as opposed to row-by-row):</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  table.defragment();
</code></pre></div>
<p>before calling <code>write()</code> on the encompassing HDU.</p><hr />
<p><a name="fits-headers"></a></p></section></section><section>
<h2><a name="FITS_headers"></a>FITS headers</h2>
<ul>

<li><a href="#accessing-header-values">Accessing header values</a></li>
<li><a href="#standard-and-conventional-fits-header-keywords">Standard and conventional FITS header keywords</a></li>
<li><a href="#long-string-values">Long string values</a></li>
<li><a href="#hierarch-style-header-keywords">HIERARCH-style header keywords</a></li>
<li><a href="#checksums">Checksums</a></li>
<li><a href="#preallocated-header-space">Preallocated header space</a></li>
<li><a href="#standard-compliance">Standard compliance</a></li>
</ul>
<p>The metadata that describes the FITS files contents is stored in the headers of each HDU.</p>
<p><a name="accessing-header-values"></a></p><section>
<h3><a name="Accessing_header_values"></a>Accessing header values</h3>
<p>There are two basic ways to access data contained in FITS headers:</p><section>
<h4><a name="A._Direct_access_header_values"></a>A. Direct access header values</h4>
<p>If you are not concerned with the internal ordering of the header you can get values from the header using the
<code>get...Value()</code> methods. To set values use the <code>addValue()</code> method.</p>
<p>To find out the telescope used you might want to know the value of the <code>TELESCOP</code> key.</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;img.fits&quot;)
  Header header = f.getHDU(0).getHeader();
  String telescope =  header.getStringValue(&quot;TELESCOP&quot;);
</code></pre></div>
<p>Or if we want to know the RA of the center of the image:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  double ra = header.getDoubleValue(&quot;CRVAL1&quot;); 
</code></pre></div>
<p>[The FITS WCS convention is being used here. For typical images the central coordinates are in the pair of keys,
<code>CRVAL1</code> and <code>CRVAL2</code> and our example assumes an equatorial coordinate system.]</p>
<p>Perhaps we have a FITS file where the RA was not originally known, or for which we&#x2019;ve just found a correction.</p>
<p>To add or change the RA we use:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  header.addValue(&quot;CRVAL1&quot;, updatedRA, &quot;Corrected RA&quot;);
</code></pre></div>
<p>The second argument is our new RA. The third is a comment field that will also be written to that header in the space
remaining.</p></section><section>
<h4><a name="B._Iterator-based_access_of_header_values"></a>B. Iterator-based access of header values</h4>
<p>If you are writing files, it&#x2019;s often desirable to organize the header and include copious amount of comments and history
records. This is most easily accomplished using a header Cursor and using the <code>HeaderCard</code>.</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Cursor&lt;String, HeaderCard&gt; c = header.iterator();
</code></pre></div>
<p>returns a cursor object that points to the first card of the header. We have <code>prev()</code> and <code>next()</code> methods that allow
us to move through the header, and <code>add()</code> and <code>delete()</code> methods to add new records. The methods of <code>HeaderCard</code>
allow us to manipulate the entire current card as a single string or broken down into keyword, value and comment
components. Comment and history header cards can be created and added to the header.</p>
<p>For tables much of the metadata describes individual columns. There are a set of <code>setTableMeta()</code> methods that can be
used to help organize these as the user wishes.</p>
<p><a name="standard-and-conventional-fits-header-keywords"></a></p></section></section><section>
<h3><a name="Standard_and_conventional_FITS_header_keywords"></a>Standard and conventional FITS header keywords</h3>
<p>FITS defines a set of standard keywords, and recognizes a set of registered conventions. You can find a collection of
these under the <code>nom.tam.fits.header</code> package:</p>
<ul>

<li><code>Standard</code> &#x2013; <a class="externalLink" href="https://heasarc.gsfc.nasa.gov/docs/fcg/standard_dict.html">keywords defined by the FITS standard</a>.
Some of the standard keywords are broken out into separate enumerations by theme, as listed below:
<ul>

<li><code>DataDescription</code> &#x2013; FITS standard keywords for describing the data content</li>
<li><code>InstrumentDescription</code> &#x2013; Standard keywords for describing the instrumentation used for observing</li>
<li><code>ObservationDescription</code> &#x2013; Standard keywords that describe the observation</li>
<li><code>ObservationDurationDescription</code> &#x2013; Standard keywords for the timing of observations</li>
<li><code>Compression</code> &#x2013; Standard keywords used for describing compressed data</li>
<li><code>Checksum</code> &#x2013; Standard keywords used for data checksumming</li>
</ul>
</li>
<li><code>HierarchicalGrouping</code> &#x2013; Keywords for the
<a class="externalLink" href="https://fits.gsfc.nasa.gov/registry/grouping.html">Hierarchical Grouping Convention</a></li>
<li><code>NonStandard</code> &#x2013; Commonly used and recognized keywords that are not strictly part of the FITS standard</li>
</ul>
<p>Additionally, many organisations (or groups of organisations) have defined their own sets of FITS keywords. Some of
these can be found under the <code>nom.tam.fits-header.extra</code> package, such as:</p>
<ul>

<li><code>NOAOExt</code> &#x2013; keywords used by the National Optical Astronomy Observatory (<i>no longer available since the IRAF
project is no longer supported</i>)</li>
<li><code>SBFitsExt</code> &#x2013; <a class="externalLink" href="https://diffractionlimited.com/wp-content/uploads/2016/11/sbfitsext_1r0.pdf">Santa Barbara Instrument Group FITS Extension
(SBFITSEXT)</a>
<ul>

<li><code>MaxImDLExt</code> &#x2013; <a class="externalLink" href="https://www.cyanogen.com/help/maximdl/FITS_File_Header_Definitions.htm">MaxIm DL Astronomy and Scientific Imaging Solutions</a></li>
</ul>
</li>
<li><code>CXCExt</code> &#x2013; <a class="externalLink" href="https://cxc.harvard.edu/contrib/arots/fits/content.txt">keywords defined for the Chandra X-ray Observatory</a></li>
<li><code>STScIExt</code> &#x2013; <a class="externalLink" href="https://outerspace.stsci.edu/display/MASTDOCS/Required+Metadata">keywords used by the Space Telescope Science Institute</a></li>
</ul>
<p>You can use the standardized keywords contained in these enums to populate headers or access header values. For
example,</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  hdr.addValue(Standard.INSTRUME, &quot;My very big telescope&quot;);
  hdr.addValue(InstrumentDescription.FILTER, &quot;meade #25A Red&quot;);
  ...
</code></pre></div>
<p>The advantage of using these standardized keywords, as opposed to strings, is that they help avoid keyword typos,
since the compiler (or your IDE) will warn you if the keyword name is not recognised.</p>
<p>Some keywords contain indices that must be specified via the <code>n()</code> method. You must spececify one integer (one-based
index) for each &#x2018;n&#x2019; appearing in the keyword name. For example, to set the value of the <code>WAT9_234</code> keyword to the
string value of <code>&quot;50&quot;</code>:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  hdr.addValue(NOAOExt.WATn_nnn.n(9, 2, 3, 4), &quot;50&quot;);
</code></pre></div>
<p>For best practice, try rely on the standard keywords, or those in registered conventions, when possible.</p>
<p><a name="long-string-values"></a></p></section><section>
<h3><a name="Long_string_values"></a>Long string values</h3>
<p>The standard maximum length for string values in the header is 68 characters. As of FITS 4.0, the <a class="externalLink" href="https://fits.gsfc.nasa.gov/registry/continue_keyword.html">CONTINUE long
string convention</a> is part of the standard. And, as of
version <b>1.16</b> of this library, it is supported by default. Support for long strings can be turned off (or on again)
via <code>FitsFactory.setLongStringEnabled(boolean)</code> if necessary. If the settings is disabled, any attempt to set a header
value to a string longer than the space available for it in a single 80-character header record will throw a
<code>LongStringsNotEnabledException</code> runtime exception.</p>
<p><a name="hierarch-style-header-keywords"></a></p></section><section>
<h3><a name="HIERARCH_style_header_keywords"></a>HIERARCH style header keywords</h3>
<p>The standard FITS header keywords consists of maximum 8 upper case letters or number, plus dash <code>-</code> and underscore
<code>_</code>. The HIERARCH keyword convention allows for longer and/or hierarchical sets of FITS keywords, and/or for
supporting a somewhat more extended set of ASCII characters (in the range of <code>0x20</code> to <code>0x7E</code>).  Support for
HIERARCH-style keywords is enabled by default as of version <b>1.16</b>. HIERARCH support can be toggled if needed via
<code>FitsFactory.setUseHierarch(boolean)</code>. By default, HIERARCH keywords are converted to upper-case only (<b>cfitsio</b>
convention), so</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  HeaderCard hc = new HeaderCard(Hierarch.key(&quot;my.lower.case.keyword[!]&quot;), &quot;value&quot;, &quot;comment&quot;);
</code></pre></div>
<p>will write the header entry to FITS as:</p>

<div class="source"><pre class="prettyprint"><code>  HIERARCH MY LOWER CASE KEYWORD[!] = 'value' / comment
</code></pre></div>
<p>You can use <code>FitsFactory.getHierarchFormater().setCaseSensitive(true)</code> to allow the use of lower-case characters, and
hence enable case-sensitive keywords. After the setting, the same card will be written to FITS as:</p>

<div class="source"><pre class="prettyprint"><code>  HIERARCH my lower case keyword[!] = 'value' / comment
</code></pre></div>
<p>You may note a few other properties of HIERARCH keywords as implemented by this library:</p>
<ol style="list-style-type: decimal">

<li>

<p>The case sensitive setting (above) also determines whether or not HIERARCH keywords are converted to upper-case
upon parsing also. As such, the header entry in last example above may be referred either as
<code>HIERARCH.my.lower.case.keyword[!]</code> or as <code>HIERARCH.MY.LOWER.CASE.KEYWORD[!]</code> internally after parsing, depending on
whether case-sensitive mode is enabled or not.</p>
</li>
<li>

<p>If <code>FitsFactory</code> has HIERARCH support disabled, any attempt to define a HIERARCH-style long keyword will throw a
<code>HierarchNotEnabledException</code> runtime exception. (However, just <code>HIERARCH</code> by itself will still be allowed as a
standard 8-character FITS keyword on its own).</p>
</li>
<li>

<p>The convention of the library is to refer to HIERARCH keywords internally as a dot-separated hierarchy, preceded
by <code>HIERARCH.</code>, e.g. <code>HIERARCH.my.keyword</code>. (The static methods of the <code>Hierarch</code> class can make it easier to create
such keywords).</p>
</li>
<li>

<p>The HIERARCH keywords may contain all printable standard ASCII characters that are allowed in FITS headers (<code>0x20</code>
thru <code>0x7E</code>). As such, we take a liberal reading of the ESO convention, which designated only upper-case letters,
numbers, plus dash <code>-</code> and underscore <code>_</code>. If you want to conform to the ESO convention more closely, you should
avoid using characters outside of the set of the original convention.</p>
</li>
<li>

<p>The library adds a space between the keywords and the <code>=</code> sign, as prescribed by the <b>cfitsio</b> convention. The
original ESO convention does not require such a space (but certainly allows for it). We add the extra space to offer
better compatibility with <b>cfitsio</b>.</p>
</li>
<li>

<p>The HIERARCH parsing is tolerant, and does not care about extra space (or spaces) between the hierarchical
components or before <code>=</code>. It also recognises <code>.</code> as a separator of hierarchy besides the conventional white space.
As such the following may all appear in a FITS header to define the same two-component keyword:</p>
</li>
</ol>

<div class="source"><pre class="prettyprint"><code>  HIERARCH MY KEYWORD
</code></pre></div>

<div class="source"><pre class="prettyprint"><code>  HIERARCH MY.KEYWORD
</code></pre></div>

<div class="source"><pre class="prettyprint"><code>  HIERARCH MY .. KEYWORD
</code></pre></div>
<p><a name="checksums"></a></p></section><section>
<h3><a name="Checksums"></a>Checksums</h3>
<p>Checksums can be added to (and updated in) the headers of HDUs to allow checking the integrity of the FITS data at a
later time.</p>
<p>As of version <b>1.17</b>, it is also possible to apply incremental updates to existing checksums. See the various static
methods of the <code>nom.tam.utilities.FitsChecksum</code> class on updating checksums for modified headers or data. There are
also methods to simplify verification of checksums when reading FITS files, and for calculating checksums directly
from a file without the need for reading and storing potentially huge amounts of data in RAM. Calculating data
checksums directly from the file is now default (as of <b>1.17</b>) for data that is in deferred read mode (i.e. not
currently loaded into RAM), making it possible to checksum huge FITS files without having to load entire segments of
data into RAM at any point.</p>
<p>Setting the checksums (<code>CHECKSUM</code> and <code>DATASUM</code> keywords) should be the last modification to the FITS object or HDU
before writing. Here is an example of settting a checksum for an HDU before you write it to disk:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  BasicHDU&lt;?&gt; hdu;
         
  // ... prepare the HDU and header ...
   
  hdu.setChecksum();
  hdu.write(...);
</code></pre></div>
<p>Or you can set checksums for all HDUs in your <code>Fits</code> in one go before writing the entire <code>Fits</code> object out to disk:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f;
  
  // ... Compose the FITS with the HDUs ...
  
  f.setChecksum();
  f.write(...);
</code></pre></div>
<p>Then later, as of version <b>1.18.1</b>, you can verify the integrity of FITS files using the stored checksums (or data
sums) just as easily too:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  try (Fits f = new Fits(&quot;huge-file.fits&quot;)) {
      f.verifyIntegrity();
  } catch (FitsIntegrityException e) {
      // Failed integrity check
  } catch (...)
      // some other error...
  }
</code></pre></div>
<p>The above will calculate checksums for each HDU directly from the file without reading the potentially large data into
memory, and compare HDU checksums and/or data checksums to those stored in the FITS headers. The verification can also
be performed on stream inputs, but unlike for files data will be invariable loaded into memory (at least temporarily).</p>
<p>You can also verify the integrity of HDUs or their data segments individually, via <code>BasicHDU.verifyIntegrity()</code> or
<code>BasicHDU.verifyDataIntegrity()</code> calls on specific HDUs.</p>
<p>Finally, you might want to update the checksums for a FITS you modify in place:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;my.fits&quot;);
  
  // We'll modify the fist HDU...
  ImageHDU im = (ImageHDU) f.readHDU();
  float[][] data = (float[][]) im.getData():
  
  // Offset the data by 1.12
  for (int i = 0; i &lt; data.length; i++) 
      for (int j = 0; i &lt; data[0].length; j++)
          data[i][j] += 1.12;
    
  // Calculate new checksums for the HDU      
  im.setChecksum();
  im.rewrite();
</code></pre></div>
<p>Or, (re)calculate and set checksums for all HDUs in a FITS file, once again leaving deferred data in unloaded state
and computing the checksums for these directly from disk:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = new Fits(&quot;my.fits&quot;);
  f.setChecksum();
  f.rewrite();
</code></pre></div>
<p>The above will work as expected provided the original FITS already had <code>CHECKSUM</code> and <code>DATASUM</code> keys in the HDUs,
or else the headers had enough unused space for adding these without growing the size of the headers. If any of the
headers or data in the <code>Fits</code> have changed size, the <code>Fits.rewrite()</code> call will throw a <code>FitsException</code> without
modifying any of the records. In such cases You may proceed re-writing a selection of the HDUs, or else write the
<code>Fits</code> to a new file with a different size.</p>
<p><a name="preallocated-header-space"></a></p></section><section>
<h3><a name="Preallocated_header_space"></a>Preallocated header space</h3>
<p>Many FITS files are created by live-recording of data, e.g. from astronomical instruments. As such not all header
values may be defined when writing the data segment of the HDU that follows the header. For example, we do not know
in advance how many rows the binary table will contain, which will depend on when the recording stops at a later
point. Other metadata may simply not be provided until a later time. For this reason version 4.0 of the FITS
standard has specified preallocating header space as some number of blank header records between the last defined
header entry and the <code>END</code> keyword.</p>
<p>As of version <b>1.16</b>, this library supports preallocated header space via <code>Header.ensureCardSpace(int)</code>, which can
be used to ensure that the header can contain <i>at least</i> the specified number of 80-character records when written to
the output. (In reality it may accommodate somewhat more than that because of the required padding to multiples of
2880 bytes or 36 records &#x2013; and you can use <code>Header.getMinimumSize()</code> to find out just how many bytes are
reserved / used by any header object at any point).</p>
<p>Once the space has been reserved, the header can be written to the output, and one may begin recording data after it.
Cards may be filled later, up to the number of records defined (and sometimes beyond), and the header can be
rewritten at a later point in place, with the additional entries.</p>
<p>For example,</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  FitsFile out = new FitsFile(&quot;mydata.fits&quot;, &quot;rw&quot;);
  
  Header h = new Header();
  
  // We want to keep room for 200 80-character records in total
  // to be filled later
  h.ensureCardSpace(200);

  // We can now write the header, knowing we can fill it with up to
  // 200 records in total at a later point
  h.write(out);
</code></pre></div>
<p>Now you can proceed to recording the data, such as a binary table row-by-row. Once you are done with it, you can go
back and make edits to the header, adding more header cards, in the space you reserved earlier, and rewrite the
header in front of the data without issues:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  // Once the data has been recorded we can proceed to fill in 
  // the additional header values, such as the end time of observation
  h.addValue(&quot;DATE-END&quot;, FitsDate.getFitsDateString(), &quot;end of observation&quot;);
  
  // And we can re-write the header in place
  h.rewrite();
</code></pre></div>
<p>Preallocated header space is also preserved when reading the data in. When parsing headers trailing blank header
records (before the <code>END</code> key) are counted as reserved card space. (Internal blank cards, between two regular keyword
entries, are however preserved as blank comment cards and their space will not be reusable unless these cards are
explicitly removed first). After reading a header with preallocated space, the user can add at least as many new cards
into that header as trailing blank records were found, and still call <code>rewrite()</code> on that header without any problems.</p>
<p><a name="standard-compliance"></a></p></section><section>
<h3><a name="Standard_compliance"></a>Standard compliance</h3>
<p>As of version <b>1.16</b>, the library offers a two-pronged approach to ensure header compliance to the
<a class="externalLink" href="#https://fits.gsfc.nasa.gov/fits_standard.html">FITS standard</a>.</p>
<ul>

<li>

<p>First, we fully enforce the standards when creating FITS headers using this library, and we do it in a way that is
compliant with earlier FITS specifications (prior to 4.0) also. We will prevent the creation of non-standard header
entries (cards) by throwing appropriate runtime exceptions (such as <code>IllegalArgumentException</code>, <code>LongValueException</code>,
<code>LongStringsNotEnabledException</code>, <code>HierarchNotEnabledException</code>) as soon as one attempts to set a header component
that is not supported by FITS or by the set of standards selected in the current <code>FitsFactory</code> settings.</p>
</li>
<li>

<p>Second, we offer the choice between tolerant and strict interpretation of 3rd-party FITS headers when parsing these.
In tolerant mode (default), the parser will do its best to overcome standard violations as much as possible, such that
the header can be parsed as fully as possible, even if some entries may have malformed content. The user may enable <code>Header.setParserWarningsEnabled(true)</code> to log each violation detected by the parser as warnings, so these can be
inspected if the user cares to know. Stricter parsing can be enabled by <code>FitsFactory.setAllowHeaderRepairs(false)</code>.
In this mode, the parser will throw an exception when it encounters a severely corrupted header entry, such as a
string value with no closing quote (<code>UnclosedQuoteException</code>) or a complex value without a closing bracket
(<code>IllegalArgumentException</code>). Lesser violations can still be logged, the same way as in tolerant mode.</p>
</li>
</ul>
<p>Additionally, we provide <code>HeaderCard.sanitize(String)</code> method that the user can call to ensure that a Java <code>String</code>
can be used in FITS headers. The method will replace illegal FITS characters (outside of the range of <code>0x20</code> thru
<code>0x7E</code>) with <code>?</code>.</p><hr />
<p><a name="compression-support"></a></p></section></section><section>
<h2><a name="Compression_support"></a>Compression support</h2>
<ul>

<li><a href="#file-compression">File level compression</a></li>
<li><a href="#image-compression">Image compression</a></li>
<li><a href="#table-compression">Table compression</a></li>
</ul>
<p>Starting with version <b>1.15</b> we include support for compressing images and tables. The compression algorithms have
been ported to Java from <b>cfitsio</b> to provide a pure 100% Java implementation. However, versions prior to <b>1.18</b>
had a number of lingering compression related bugs of varying severity, which may have prevented realiable use.</p>
<p><a name="file-compression"></a></p><section>
<h3><a name="File_level_compression"></a>File level compression</h3>
<p>It is common practice to compress FITS files using <b>gzip</b> (<code>.gz</code> extension) so they can be exchanged in a more
compact form. The library supports the creation of gzipped fits out of the box, by wrapping the file's output
stream into a <code>GZIPOutputStream</code> or , such as:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  Fits f = ...
  
  FitsOutputStream out = new FitsOutputStream(new GZIPOutputStream(
  	new FileOutputStream(new File(&quot;mydata.fits.gz&quot;))));
  f.write(out);
</code></pre></div>
<p>While we only support GZIP compression for writing compressed files (thanks to Java's support out of the box), we can
read more compressed formats using Apaches commons-compress library. We support reading compressed files produced via
<b>gzip</b> (<code>.gz</code>), the Linux <b>compress</b> tools (<code>.Z</code>), and via <b>bzip2</b> (<code>.bz2</code>). The decompression happens
automatically when we construct a <code>Fits</code> object with an input stream:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  new FileInputStream compressedStream = new FileInputStream(new File(&quot;image.fits.bz2&quot;));
 
  // The input stream will be filtered through a decompression algorithm
  // All read access to the FITS will pass through that decompression...
  Fits fits = new Fits(compressedStream);
  ...
</code></pre></div>
<p><a name="image-compression"></a></p></section><section>
<h3><a name="Image_compression"></a>Image compression</h3>
<p>Image compression and tiling are fully supported by nom-tam-fits as of <b>1.18</b>, including images of
any dimensionality and rectangular morphologies. (Releases between <b>1.15</b> and <b>1.17</b> had partial image
compression support for 2D square images only, while some quantization support for compression was
lacking prior to <b>1.18</b>).</p>
<p>The tiling of non-2D images follows the
<a class="externalLink" href="https://heasarc.gsfc.nasa.gov/docs/software/fitsio/compression.html">CFITSIO convention</a> with 2D tiles,
where the tile size is set to 1 in the higher dimensions.</p>
<p>Compressing an image HDU is typically a multi-step process:</p>
<ol style="list-style-type: decimal">

<li>Create a <code>CompressedImageHDU</code>, e.g. with <code>fromImageHDU(ImageHDU, int...)</code>:</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">  ImageHDU image = ...
 
  CompressedImageHDU compressed = CompressedImageHDU.fromImageHDU(image, 60, 40);
</code></pre></div>
<ol style="list-style-type: decimal">

<li>Set up the compression algorithm, including quantization (if desired) via <code>setCompressAlgorithm(String)</code> and
<code>setQuantAlgorithm(String)</code>, and optionally the compressiomn method used for preserving the blank values via
<code>preserveNulls(String)</code>:</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">  compressed.setCompressAlgorithm(Compression.ZCMPTYPE_RICE_1)
            .setQuantAlgorithm(Compression.ZQUANTIZ_SUBTRACTIVE_DITHER_1)
            .preserveNulls(Compression.ZCMPTYPE_HCOMPRESS_1);
</code></pre></div>
<ol style="list-style-type: decimal">

<li>Set compression (and quantization) options, via calling on <code>getCompressOption(Class)</code>:</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">  compressed.getCompressOption(RiceCompressOption.class).setBlockSize(32);
  compressed.getCompressOption(QuantizeOption.class).setBZero(3.0).setBScale(0.1).setBNull(-999);
</code></pre></div>
<ol style="list-style-type: decimal">

<li>Finally, perform the actual compression via <code>compress()</code>:</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">  compressed.compress(); 
</code></pre></div>
<p>After the compression, the compressed image HDU can be handled just like any other HDU, and written to a file
or stream, for example (just not as the first HDU in a FITS&#x2026;).</p>
<p>The reverse process is simply via the <code>asImageHDU()</code> method. E.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  CompressedImageHDU compressed = ...
  ImageHDU image = compressed.asImageHDU();
</code></pre></div>
<p>When compressing or decompression images, all available CPUs are automatically utilized.</p><section>
<h4><a name="Accessing_image_header_values_without_decompressing:"></a>Accessing image header values without decompressing:</h4>
<p>You don't need to decompress the image to see what the decompressed image header is.
You can simply call <code>CompressedImageHDU.getImageHeader()</code> to peek into the reconstructed header of
the image before it was compressed:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  CompressedImageHDU compressed = ...
  Header imageHeader = compressed.getImageHeader();
</code></pre></div></section><section>
<h4><a name="Accessing_specific_parts_of_a_compressed_image"></a>Accessing specific parts of a compressed image</h4>
<p>Often compressed images can be very large, and we are interested in specific areas of it only.
As such, we do not want to decompress the entire image. In these cases we can use the <code>getTileHDU()</code>
method of <code>CompressedImageHDU</code>
class to decompress only the selected image area. As of version <b>1.18</b>, this is really easy also:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">  CompressedImageHDU compressed = ...
   
  int[] fromPixels = ...
  int[] cutoutSize = ...
   
  ImageHDU cutout = compressed.getTileHDU(fromPixels, cutoutSize);
</code></pre></div>
<p><a name="table-compression"></a></p></section></section><section>
<h3><a name="Table_compression"></a>Table compression</h3>
<p>Table compression is also supported in nom-tam-fits from version <b>1.15</b>, and more completely since
<b>1.18</b>. When compressing a table &#x2018;tiles&#x2019; that are sets of contiguous rows within a column. The compression
algorithms are the same as the ones provided for image compression. Default compression is <code>GZIP_2</code>.
(In principle, every column could use a different algorithm.)</p>
<p>Tile compression mimics image compression, and is typically a 2-step process:</p>
<ol style="list-style-type: decimal">

<li>Create a <code>CompressedTableHDU</code>, e.g. with <code>fromBinaryTableHDU(BinaryTableHDU, int, String...)</code>, using the
specified number of table rows per compressed block, and compression algorithm(s):</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">   BinaryTableHDU table = ...
   CompressedTableHDU compressed = CompressedTableHDU.fromBinaryTableHDU(table, 4, Compression.GZIP_2);
</code></pre></div>
<ol style="list-style-type: decimal">

<li>Perform the compression via <code>compress()</code>:</li>
</ol>

<div class="source"><pre class="prettyprint"><code class="language-java">   compressed.compress();
</code></pre></div>
<p>The two step process (as opposed to a single-step one) was probably chosen because it mimics that of
<code>CompressedImageHDU</code>, where further configuration steps may be inserted in-between. But, of course we can combine the
steps into a single line:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   CompressedTableHDU compressed = CompressedTableHDU.fromBinaryTableHDU(table, 4, Compression.GZIP_2).compress();
</code></pre></div>
<p>After the compression, the compressed table HDU can be handled just like any other HDU, and written to a file or
stream, for example.</p>
<p>The reverse process is simply via the <code>asBinaryTableHDU()</code> method. E.g.:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">    CompressedTableHDU compressed = ...
    BinaryTableHDU table = compressed.asBinaryTableHDU();
</code></pre></div><section>
<h4><a name="Accessing_image_header_values_without_decompressing"></a>Accessing image header values without decompressing</h4>
<p>You don't need to decompress the table to see what the decompressed table header is. You can simply call <code>CompressedTableHDU.getTableHeader()</code> to peek into the reconstructed header of the original table before it was
compressed:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   CompressedTableHDU compressed = ...
   Header origHeader = compressed.getTableHeader();
</code></pre></div></section><section>
<h4><a name="Decompressing_select_parts_of_a_compressed_binary_table"></a>Decompressing select parts of a compressed binary table</h4>
<p>Sometimes we are interested in a section of the compressed table only. As of version <b>1.18</b>, this is really easy
also. If you just want to uncompress a range of the compressed tiles, you can</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   CompressedImageHDU compressed = ...
   TableHDU section = compressed.asTableHDU(fromTile, toTile);
</code></pre></div>
<p>The resulting HDU will contain all columns but on only the uncompressed rows for the selected tiles.</p>
<p>And, if you want to surgically access a range of data from select columns (and tiles) only:</p>

<div class="source"><pre class="prettyprint"><code class="language-java">   CompressedImageHDU compressed = ...
   Object[] colData = compressed.getColumnData(colIndex, fromTile, toTile);
</code></pre></div><hr />
<p><a name="contribute"></a></p></section></section></section><section>
<h2><a name="How_to_contribute"></a>How to contribute</h2>
<p>The <i>nom-tam-fits</i> library is a community-maintained project. We absolutely rely on developers like you to make it
better and to keep it going. Whether there is a nagging issue you would like to fix, or a new feature you'd like to
see, you can make a difference yourself. We welcome you as a contributor. More than that, we feel like you became part
of our community the moment you landed on this page. We very much encourange you to make this project a little bit
your own, by submitting pull requests with fixes and enhancement. When you are ready, here are the typical steps for
contributing to the project:</p>
<ol style="list-style-type: decimal">

<li>

<p>Old or new <b>Issue</b>? Whether you just found a bug, or you are missing a much needed feature, start by checking
open (and closed) <a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits/issues">Issues</a>. If an existing issue seems like a
good match to yours, feel free to raise your hand and comment on it, to make your voice heard, or to offer help in
resolving it. If you find no issues that match, go ahead and create a new one.</p>
</li>
<li>

<p><b>Fork</b>. Is it something you'd like to help resolve? Great! You should start by creating your own fork of the
repository so you can work freely on your solution. We also recommend that you place your work on a branch of your
fork, which is named either after the issue number, e.g. <code>issue-192</code>, or some other descriptive name, such as
<code>implement-foreign-hdu</code>.</p>
</li>
<li>

<p><b>Develop</b>. Feel free to experiment on your fork/branch. If you run into a dead-end, you can always abandon it
(which is why branches are great) and start anew. You can run your own test builds locally using <code>mvn clean test</code>
before committing your changes. If the tests pass, you should also try running <code>mvn clean package</code> and
<code>mvn site stage</code> to ensure that the package and javadoc are also in order. Remember to synchronize your <code>master</code>
branch by fetching changes from upstream every once in a while, and merging them into your development branch. Don't
forget to:</p>
<ul>

<li>

<p>Add <b>Javadoc</b> your new code. You can keep it sweet and simple, but make sure it properly explains your methods,
their arguments and return values, and why and what exceptions may be thrown. You should also cross-reference other
methods that are similar, related, or relevant to what you just added.</p>
</li>
<li>

<p>Add <b>Unit Tests</b>. Make sure your new code has as close to full unit test coverage as possible. You should aim
for 100% diff coverage. When pushing changes to your fork, you can get a coverage report by checking the Github
Actions result of your commit (click the Codecov link), and you can analyze what line(s) of code need to have tests
added. Try to create tests that are simple but meaningful (i.e. check for valid results, rather than just confirm
existing behavior), and try to cover as many realistic scenarios as appropriate. Write lots of tests if you need to.
It's OK to write 100 lines of test code for 5 lines of change. Go for it! And, you will get extra kudos for filling
unit testing holes outside of your area of development!</p>
</li>
</ul>
</li>
<li>

<p><b>Pull Request</b>. Once you feel your work can be integrated, create a pull request from your fork/branch. You can
do that easily from the github page of your fork/branch directly. In the pull request, provide a concise description
of what you added or changed. Your pull request will be rewied. You may get some feedback at this point, and maybe
there will be discussions about possible improvements or regressions etc. It's a good thing too, and your changes will
likely end up with added polish as a result. You can be all the more proud of it in the end!</p>
</li>
<li>

<p>If all goes well, your pull-request will get merged, and will be included in the upcoming release of
<i>nom-tam-fits</i>. Congratulations for your excellent work, and many thanks for dedicating some of your time for making
this library a little bit better. There will be many who will appreciate it. :-)</p>
</li>
</ol>
<p>If at any point you have questions, or need feedback, don't be afraid to ask. You can put your questions into the
issue you found or created, or your pull-request, or as a Q&amp;A in
<a class="externalLink" href="https://github.com/nom-tam-fits/nom-tam-fits/discussions">Discussions</a>.</p></section>
        </main>
      </div>
    </div>
    <hr/>
    <footer>
      <div class="container-fluid">
        <div class="row-fluid">
            <p>&#169;      1996&#x2013;2023
nom-tam-fits
</p>
        </div>
      </div>
    </footer>
  </body>
</html>
